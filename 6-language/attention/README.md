# **ATTENTION**

The task is to build a *Masked Language Model*, where a language model is trained to predict a "masked" word that is missing from the sequence of text. A Pre-Trained Model, **BERT**, a transformer-based language model developed by Google, will be used. The language model was trained to predict a masked word based on the surrounding context words. 